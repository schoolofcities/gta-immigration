{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcb4ce5-793e-4511-acc9-9e11e3a0c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaa3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEN_YEARS = [\n",
    "    1951, 1956, 1961, 1966, 1971, 1976, 1981, 1986, 1991, 1996, \n",
    "    2001, 2006, 2011, 2016, 2021\n",
    "]\n",
    "\n",
    "FED_YEARS = [1952, 1966, 1976, 1987, 1996, 1999, 2003, 2013]\n",
    "ONTED_YEARS = [1962, 1966, 1975, 1987, 1996, 2005, 2015]\n",
    "\n",
    "FELXN_YEARS = [\n",
    "    1962, 1963, 1965, 1968, 1972, 1974, 1979, 1980, 1984, 1988, \n",
    "    1993, 1997, 2000, 2004, 2006, 2008, 2011, 2015, 2019, 2021\n",
    "]\n",
    "ONTELXN_YEARS = [\n",
    "    1963, 1967, 1971, 1975, 1977, 1981, 1985, 1987, 1990, 1995, \n",
    "    1999, 2003, 2007, 2011, 2014, 2018, 2022\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d2f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_CODES = {\n",
    "    1951: {\n",
    "        'num_pop_tot': ['pop__tot1951ttd'],\n",
    "        'num_imm_tot': [],\n",
    "        'num_imm_new': [],\n",
    "        'avg_hou_inc': [],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': [],\n",
    "    }, \n",
    "    1956: {\n",
    "        'num_pop_tot': ['pop__tot1956ttd'],\n",
    "        'num_imm_tot': [],\n",
    "        'num_imm_new': [],\n",
    "        'avg_hou_inc': [],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': [],\n",
    "    }, \n",
    "    1961: {\n",
    "        'num_pop_tot': ['pop__tot1961ttd'],\n",
    "        'num_imm_tot': ['imb__tot1961ttd'],\n",
    "        'num_imm_new': ['impi19611961tt1', 'impi19601961tt1', 'impi195819591961tt1', 'impi195619571961tt1', 'impi195119551961tt1'],\n",
    "        'avg_hou_inc': [],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': [],\n",
    "    }, \n",
    "    1966: {\n",
    "        'num_pop_tot': ['pop__tot1966ttd'],\n",
    "        'num_imm_tot': [],\n",
    "        'num_imm_new': [],\n",
    "        'avg_hou_inc': [],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': [],\n",
    "    }, \n",
    "    1971: {\n",
    "        'num_pop_tot': ['pop__tot1971ttd'],\n",
    "        'num_imm_tot': ['imb__tot1971ttd'],\n",
    "        'num_imm_new': [],\n",
    "        'avg_hou_inc': ['ihat_avg1971ttn'],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__1971tt1', 'lnh_1resoffifr__1971tt1'],\n",
    "    }, \n",
    "    1976: {\n",
    "        'num_pop_tot': ['pop__tot1976ttd'],\n",
    "        'num_imm_tot': [],\n",
    "        'num_imm_new': [],\n",
    "        'avg_hou_inc': [],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': [],\n",
    "    }, \n",
    "    1981: {\n",
    "        'num_pop_tot': ['pop__tot1981ttd'],\n",
    "        'num_imm_tot': ['imag_tot1981ttd'],\n",
    "        'num_imm_new': ['impi197819811981tt1', 'impi197019771981tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg1981ttn'],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__1981tt1', 'lnh_1resoffifr__1981tt1'],\n",
    "    }, \n",
    "    1986: {\n",
    "        'num_pop_tot': ['pop__tot1986ttd'],\n",
    "        'num_imm_tot': ['imb__tot1986ttd'],\n",
    "        'num_imm_new': ['impi198319861986tt1', 'impi197819821986tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg1986ttn'],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__1986tt1', 'lnh_1resoffifr__1986tt1'],\n",
    "    }, \n",
    "    1991: {\n",
    "        'num_pop_tot': ['pop__tot1991ttd'],\n",
    "        'num_imm_tot': ['imd__tot1991ttd'],\n",
    "        'num_imm_new': ['impi198819911991tt1', 'impi198119871991tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg1991ttn'],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__1991tt1', 'lnh_1resoffifr__1991tt1'],\n",
    "    }, \n",
    "    1996: {\n",
    "        'num_pop_tot': ['pop__tot1996ttd'],\n",
    "        'num_imm_tot': ['imb__tot1996ttd'],\n",
    "        'num_imm_new': ['impi199119961996tt1', 'impi198119901996tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg1996ttn'],\n",
    "        'num_not_vm_tot': [],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__1996tt1', 'lnh_1resoffifr__1996tt1', 'lnh_mresenfr1996tt1'],\n",
    "    }, \n",
    "    2001: {\n",
    "        'num_pop_tot': ['pop__tot2001ttd'],\n",
    "        'num_imm_tot': ['imb__tot2001ttd'],\n",
    "        'num_imm_new': ['impi199620012001tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg2001ttn'],\n",
    "        'num_not_vm_tot': ['vminnvis2001tt1'],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__2001tt1', 'lnh_1resoffifr__2001tt1', 'lnh_mresenfr2001tt1'],\n",
    "    }, \n",
    "    2006: {\n",
    "        'num_pop_tot': ['pop__tot2006ttd'],\n",
    "        'num_imm_tot': ['imb__tot2006ttd'],\n",
    "        'num_imm_new': ['impi200120062006tt1', 'impi199620002006tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg2006ttn'],\n",
    "        'num_not_vm_tot': ['vminnvis2006tt1'],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__2006tt1', 'lnh_1resoffifr__2006tt1', 'lnh_mresenfr2006tt1'],\n",
    "    }, \n",
    "    2011: {\n",
    "        'num_pop_tot': ['pop__tot2011ttd'],\n",
    "        'num_imm_tot': ['imb__tot2011ttd'],\n",
    "        'num_imm_new': ['impi200620112011tt1', 'impi200120052011tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg2011ttn'],\n",
    "        'num_not_vm_tot': ['vminnvis2011tt1'],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__2011tt1', 'lnh_1resoffifr__2011tt1', 'lnh_mresenfr2011tt1'],\n",
    "    }, \n",
    "    2016: {\n",
    "        'num_pop_tot': ['pop__tot2016ttd'],\n",
    "        'num_imm_tot': ['imb__tot2016ttd'],\n",
    "        'num_imm_new': ['impi201120162016tt1', 'impi200620102016tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg2016ttn'],\n",
    "        'num_not_vm_tot': ['vminnvis2016tt1'],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__2016tt1', 'lnh_1resoffifr__2016tt1', 'lnh_mresenfr2016tt1'],\n",
    "    }, \n",
    "    2021: {\n",
    "        'num_pop_tot': ['pop__tot2021ttd'],\n",
    "        'num_imm_tot': ['imb__tot2021ttd'],\n",
    "        'num_imm_new': ['impi201620212021tt1', 'impi201120152021tt1'],\n",
    "        'avg_hou_inc': ['ihat_avg2021ttn'],\n",
    "        'num_not_vm_tot': ['vminnvis2021tt1'],\n",
    "        'num_enfr_home_tot': ['lnh_1resoffien__2021tt1', 'lnh_1resoffifr__2021tt1', 'lnh_mresenfr2021tt1'],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9f9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_year(year):\n",
    "    \"\"\"\n",
    "    Returns the appropriate census year based on different rules for different periods:\n",
    "    - Before 1961: return 1961\n",
    "    - 1961-1980: round down to decade + 1 (1961, 1971)\n",
    "    - After 1981: round down to nearest 5 + 1 (1981, 1986, 1991, etc.)\n",
    "    \n",
    "    Examples:\n",
    "    1955 -> 1961\n",
    "    1965 -> 1961\n",
    "    1975 -> 1971\n",
    "    1980 -> 1971\n",
    "    1987 -> 1986\n",
    "    2003 -> 2001\n",
    "    \"\"\"\n",
    "    if year < 1961:\n",
    "        return 1961\n",
    "    elif year <= 1980:\n",
    "        return year - ((year - 1961) % 10)\n",
    "    else:\n",
    "        return year - ((year - 1951) % 5)\n",
    "\n",
    "def get_ed_year(year, is_ontario=True):\n",
    "    \"\"\"\n",
    "    Returns the most recent electoral district year prior to the input year.\n",
    "    \n",
    "    Args:\n",
    "        year (int): The year to look up\n",
    "        is_ontario (bool): If True, use Ontario electoral districts years,\n",
    "                       if False, use Federal electoral district years\n",
    "    \n",
    "    Returns:\n",
    "        int: The most recent electoral district year\n",
    "\n",
    "    Examples:\n",
    "        get_ed_year(1962, is_ontario=True) -> 1962\n",
    "        get_ed_year(1962, is_ontario=False) -> 1952\n",
    "        get_ed_year(2003, is_ontario=True) -> 1996\n",
    "        get_ed_year(2003, is_ontario=False) -> 2003\n",
    "    \"\"\"\n",
    "    years = ONTED_YEARS if is_ontario else FED_YEARS\n",
    "    valid_years = [y for y in years if y <= year]\n",
    "    if not valid_years:\n",
    "        return years[0]  # Return earliest year if input year is before all valid years\n",
    "    return max(valid_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d40c2",
   "metadata": {},
   "source": [
    "Create approximations for each of the census variables under consideration, for each election year. We want this at the level of electoral districts and approximated from census tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce239a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_census_values_to_gdf(gdf_full, gdf_small, cen_year, cen_var):\n",
    "    cols = YEAR_CODES[cen_year][cen_var]\n",
    "\n",
    "    if len(cols) == 0:  \n",
    "        gdf_small[cen_var] = np.nan\n",
    "        if cen_var == 'num_not_vm_tot':\n",
    "            gdf_small.rename(columns={'num_not_vm_tot': 'num_vm_tot'}, inplace=True)\n",
    "    elif len(cols) > 1:\n",
    "        gdf_small.loc[:, cen_var] = gdf_full.loc[:, cols].sum(axis=1)\n",
    "    elif cen_var == 'num_not_vm_tot':\n",
    "        pop_total = gdf_full[YEAR_CODES[cen_year]['num_pop_tot'][0]]\n",
    "        non_vm_total = gdf_full[cols[0]]  # Use [0] to get string from list\n",
    "        gdf_small['num_vm_tot'] = pop_total - non_vm_total\n",
    "    else:\n",
    "        gdf_small.loc[:, cen_var] = gdf_full.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce863f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ed_stats(gdf_ed_gta, gdf_ct_gta, df_ct_cen, cen_year):\n",
    "    gdf_ct_gta['geosid'] = gdf_ct_gta['geosid'].astype(str)\n",
    "    df_ct_cen['geosid'] = df_ct_cen['geosid'].astype(str)\n",
    "    df_ct_cen['geosid'] = df_ct_cen['geosid'].apply(lambda x: x[:-2] + '.00' if x.endswith('.0') else x)\n",
    "\n",
    "    gdf_full = pd.merge(\n",
    "        gdf_ct_gta,\n",
    "        df_ct_cen,\n",
    "        on='geosid',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    gdf_small = gdf_full[['geosid', 'geometry']].copy()\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'num_pop_tot')\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'num_imm_tot')\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'num_imm_new')\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'avg_hou_inc')\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'num_not_vm_tot')\n",
    "    add_census_values_to_gdf(gdf_full, gdf_small, cen_year, 'num_enfr_home_tot')\n",
    "\n",
    "    # Find intersections between census tracts and electoral districts\n",
    "    pairs = gpd.sjoin(gdf_small, gdf_ed_gta, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Calculate area weights for overlapping geometries\n",
    "    pairs['overlap_area'] = pairs.apply(\n",
    "        lambda row: row['geometry'].intersection(\n",
    "            gdf_ed_gta.loc[row['index_right'], 'geometry']\n",
    "        ).area / row['geometry'].area,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # List of columns to aggregate (excluding geosid, geometry)\n",
    "    value_columns = [col for col in gdf_small.columns \n",
    "                    if col not in ['geosid', 'geometry']]\n",
    "\n",
    "    # Initialize result dataframe with electoral district geometries\n",
    "    result = gdf_ed_gta.copy()\n",
    "\n",
    "    # Calculate weighted sums for each value column\n",
    "    for col in value_columns:\n",
    "        if pairs[col].isna().all():  # If column is all NaN, preserve NaN in result\n",
    "            result[col] = np.nan\n",
    "        else:\n",
    "            weighted_values = pairs[col] * pairs['overlap_area']\n",
    "            result[col] = weighted_values.groupby(pairs['index_right']).sum()\n",
    "\n",
    "    # Compute relevant proportions \n",
    "    result['pct_imm'] = result['num_imm_tot'] / result['num_pop_tot']\n",
    "    result['pct_imm_new'] = result['num_imm_new'] / result['num_pop_tot']\n",
    "    result['pct_vm'] = result['num_vm_tot'] / result['num_pop_tot']\n",
    "    result['pct_enfr_home'] = result['num_enfr_home_tot'] / result['num_pop_tot']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5685b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:18<00:00,  1.09s/it]\n",
      "100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(ONTELXN_YEARS):\n",
    "    ed_year = get_ed_year(year, is_ontario=True)\n",
    "    cen_year = get_census_year(year)\n",
    "\n",
    "    gdf_onted_gta = gpd.read_file(f'../data/geo/{ed_year}_ont-ed/ont-ed_gta_{ed_year}.gpkg')\n",
    "    gdf_ct_gta = gpd.read_file(f\"../data/geo/{cen_year}_ct/ct_gta_{cen_year}.gpkg\")\n",
    "    df_ct_cen = pd.read_csv(f\"../data/census/{cen_year}_ct_wide/census_wide_{cen_year}_ct.csv\")\n",
    "\n",
    "    gdf_onted_stats = compute_ed_stats(gdf_onted_gta, gdf_ct_gta, df_ct_cen, cen_year)\n",
    "    gdf_onted_stats = gdf_onted_stats[gdf_onted_stats.ct_overlap >= 0.75]\n",
    "\n",
    "    gdf_onted_stats.to_file(f'../data/elections/{year}_ont-elxn/ont-ed_stats_{year}.gpkg')\n",
    "\n",
    "for year in tqdm(FELXN_YEARS):\n",
    "    ed_year = get_ed_year(year, is_ontario=False)\n",
    "    cen_year = get_census_year(year)\n",
    "\n",
    "    gdf_fed_gta = gpd.read_file(f'../data/geo/{ed_year}_fed/fed_gta_{ed_year}.gpkg')\n",
    "    gdf_ct_gta = gpd.read_file(f\"../data/geo/{cen_year}_ct/ct_gta_{cen_year}.gpkg\")\n",
    "    df_ct_cen = pd.read_csv(f\"../data/census/{cen_year}_ct_wide/census_wide_{cen_year}_ct.csv\")\n",
    "\n",
    "    gdf_fed_stats = compute_ed_stats(gdf_fed_gta, gdf_ct_gta, df_ct_cen, cen_year)\n",
    "    gdf_fed_stats = gdf_fed_stats[gdf_fed_stats.ct_overlap >= 0.75]\n",
    "\n",
    "    gdf_fed_stats.to_file(f'../data/elections/{year}_felxn/fed_stats_{year}.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc61f5",
   "metadata": {},
   "source": [
    "In each of the data frames for the elections which contain census approximations for each electoral District, add the vote share for that riding in the given year for the three major parties as well as an other category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffec230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_election_results(df, year):\n",
    "    import warnings\n",
    "    # Suppress specific deprecation warning for groupby operation\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning,\n",
    "                          message='DataFrameGroupBy.apply operated on the grouping columns')\n",
    "    \n",
    "    # Standardize column names (strip spaces, lowercase)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Detect Ontario elections by checking for 'Plurality' column\n",
    "    is_ontario = 'Plurality' in df.columns\n",
    "    \n",
    "    if is_ontario:\n",
    "        # Rename columns to match federal format\n",
    "        df = df.rename(columns={\n",
    "            'Electoral District': 'Constituency',\n",
    "            'Party': 'Political_Affiliation',\n",
    "            'Votes Cast': 'Votes'\n",
    "        })\n",
    "        \n",
    "        # Clean constituency names without regex\n",
    "        df['Constituency'] = df['Constituency'].str.split(' - ', n=1).str[-1]\n",
    "    \n",
    "    # Define party mappings (Ontario mappings include federal mappings as well)\n",
    "    conservative_parties = ['Progressive Conservative Party', 'Conservative Party of Canada', 'PC', 'PCP']\n",
    "    reform_parties = ['Reform Party of Canada', 'Canadian Reform Conservative Alliance']\n",
    "    liberal_party = ['Liberal Party of Canada', 'L', 'OLP', 'LIB']\n",
    "    ndp_party = ['New Democratic Party', 'ND', 'NDP']\n",
    "    \n",
    "    # Compute party vote percentages\n",
    "    def get_party_percentage(group, party_names):\n",
    "        party_votes = group[group['Political_Affiliation'].isin(party_names)]\n",
    "        if len(party_votes) > 1:\n",
    "            party_votes = party_votes.loc[party_votes['Votes'].idxmax()]\n",
    "        return party_votes['Votes'].sum() if not party_votes.empty else 0\n",
    "    \n",
    "    def compute_percentages(group):\n",
    "        total = group['Votes'].sum()\n",
    "        cons1_votes = get_party_percentage(group, conservative_parties)\n",
    "        cons2_votes = get_party_percentage(group, reform_parties)\n",
    "        lib_votes = get_party_percentage(group, liberal_party)\n",
    "        ndp_votes = get_party_percentage(group, ndp_party)\n",
    "        oth_votes = total - (cons1_votes + cons2_votes + lib_votes + ndp_votes)\n",
    "        \n",
    "        return pd.Series({\n",
    "            'constituency': group['Constituency'].iloc[0],\n",
    "            'cons1_pct': (cons1_votes / total) * 100,\n",
    "            'cons2_pct': (cons2_votes / total) * 100 if cons2_votes > 0 else np.nan,\n",
    "            'lib_pct': (lib_votes / total) * 100,\n",
    "            'ndp_pct': (ndp_votes / total) * 100,\n",
    "            'oth_pct': (oth_votes / total) * 100\n",
    "        })\n",
    "    \n",
    "    # Apply the function to group by constituency\n",
    "    df_results = (df.groupby('Constituency')\n",
    "                    .apply(compute_percentages)  \n",
    "                    .reset_index(drop=True))\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a46fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_constituency_name(df_col, year=None, is_federal=False):\n",
    "    # Federal overrides for specific years\n",
    "    federal_overrides = {\n",
    "        1972: {'High Park': 'highparkhumbervalley', 'Lakeshore': 'torontolakeshore'},\n",
    "        1974: {'High Park': 'highparkhumbervalley', 'Lakeshore': 'torontolakeshore', 'Peel South': 'mississauga'},\n",
    "        1988: {'Bramalea-Gore-Malton': 'bramptonmalton', 'Markham-Whitchurch-Stouffville': 'markham'},\n",
    "        1997: {'Bramalea-Gore-Malton-Springdale': 'bramaleagoremalton', 'Toronto-Danforth': 'broadviewgreenwood'}\n",
    "    }\n",
    "    \n",
    "    # Apply overrides if applicable\n",
    "    if is_federal and year in federal_overrides:\n",
    "        df_col = df_col.replace(federal_overrides[year])\n",
    "\n",
    "    # General processing\n",
    "    return (df_col\n",
    "            .str.replace(r'\\([^)]*\\)', '', regex=True)  # Remove content within brackets\n",
    "            .str.split('/').str[0]                     # Keep only content before slash\n",
    "            .str.strip()                                # Remove leading/trailing whitespace\n",
    "            .str.lower()                                # Convert to lowercase\n",
    "            .str.replace(r'[^a-z]', '', regex=True))   # Remove non-letter characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80c2a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:06<00:00,  2.48it/s]\n",
      "100%|██████████| 20/20 [00:13<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for year in tqdm(ONTELXN_YEARS):\n",
    "    df_elections = pd.read_csv(f'../data/elections/{year}_ont-elxn/{year}_results.csv')\n",
    "    df_elections = process_election_results(df_elections, year)\n",
    "\n",
    "    gdf_onted_stats = gpd.read_file(f'../data/elections/{year}_ont-elxn/ont-ed_stats_{year}.gpkg')\n",
    "    \n",
    "    # Create standardized name columns for joining\n",
    "    df_elections['dummy_name'] = create_dummy_constituency_name(df_elections['constituency'], year=year, is_federal=False)\n",
    "    gdf_onted_stats['dummy_name'] = create_dummy_constituency_name(gdf_onted_stats['geoname'], year=year, is_federal=False)\n",
    "    \n",
    "    # Perform left merge (keep only rows from gdf_onted_stats)\n",
    "    merged_df = pd.merge(\n",
    "        gdf_onted_stats, \n",
    "        df_elections.drop(columns=['constituency']), \n",
    "        on='dummy_name', \n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    # Check for unmatched rows from gdf_onted_stats\n",
    "    # unmatched = merged_df[merged_df['_merge'] == 'left_only']\n",
    "    # if len(unmatched) > 0:\n",
    "    #     print(year)\n",
    "    #     print(f\"\\nWarning: {len(unmatched)} electoral districts have no matching election results:\")\n",
    "    #     print(unmatched[['dummy_name', 'geoname']])\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=['_merge', 'dummy_name'])\n",
    "    gdf_onted_stats = merged_df\n",
    "\n",
    "    gdf_onted_stats.to_file(f'../data/elections/{year}_ont-elxn/ont-ed_stats_{year}.gpkg')\n",
    "\n",
    "for year in tqdm(FELXN_YEARS):\n",
    "    df_elections = pd.read_csv(f'../data/elections/{year}_felxn/{year}_results.csv')\n",
    "    df_elections = process_election_results(df_elections, year)\n",
    "\n",
    "    gdf_fed_stats = gpd.read_file(f'../data/elections/{year}_felxn/fed_stats_{year}.gpkg')\n",
    "\n",
    "    # Create standardized name columns for joining\n",
    "    df_elections['dummy_name'] = create_dummy_constituency_name(df_elections['constituency'], year=year, is_federal=True)\n",
    "    gdf_fed_stats['dummy_name'] = create_dummy_constituency_name(gdf_fed_stats['geoname'], year=year, is_federal=True)\n",
    "    \n",
    "    # Perform left merge (keep only rows from gdf_fed_stats)\n",
    "    merged_df = pd.merge(\n",
    "        gdf_fed_stats, \n",
    "        df_elections.drop(columns=['constituency']), \n",
    "        on='dummy_name', \n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    # Check for unmatched rows from gdf_fed_stats\n",
    "    # unmatched = merged_df[merged_df['_merge'] == 'left_only']\n",
    "    # if len(unmatched) > 0:\n",
    "    #     print(year)\n",
    "    #     print(f\"\\nWarning: {len(unmatched)} electoral districts have no matching election results:\")\n",
    "    #     print(unmatched[['dummy_name', 'geoname']])\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_df = merged_df[merged_df['_merge'] == 'both'].drop(columns=['_merge', 'dummy_name'])\n",
    "    gdf_fed_stats = merged_df\n",
    "\n",
    "    gdf_fed_stats.to_file(f'../data/elections/{year}_felxn/fed_stats_{year}.gpkg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
