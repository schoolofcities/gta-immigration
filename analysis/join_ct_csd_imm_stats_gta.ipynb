{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419db51c-6e0b-476a-bf1e-22c3bacbf719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e45663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import CEN_YEARS\n",
    "from constants import YEAR_CODES\n",
    "\n",
    "mpoly_GTA = gpd.read_file('../data/geo/regions/GTA.gpkg').geometry.to_list()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80f766",
   "metadata": {},
   "source": [
    "Prune geometries to select for the GTA-only versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:19<00:00, 15.47s/it]\n"
     ]
    }
   ],
   "source": [
    "cen_years_81 = [y for y in CEN_YEARS if y >= 1981]  # Prior years do not have CSD data\n",
    "\n",
    "for year in tqdm(cen_years_81):\n",
    "    gdf_csd_all = gpd.read_file(f'../data/geo/{year}_csd/csd_{year}.geojson')\n",
    "    gdf_csd_all['gta_overlap'] = gdf_csd_all.apply(lambda row: row.geometry.intersection(mpoly_GTA).area / row.geometry.area, axis=1)\n",
    "    gdf_csd_gta = gdf_csd_all[gdf_csd_all.gta_overlap >= 0.25]\n",
    "    gdf_csd_gta.to_file(f'../data/geo/{year}_csd/csd_gta_{year}.gpkg', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22561de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:42<00:00,  2.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each year, save those CT's which are in the GTA\n",
    "for year in tqdm(CEN_YEARS):\n",
    "    gdf_ct_all = gpd.read_file(f\"../data/geo/{year}_ct/ct_{year}.zip\")\n",
    "    gdf_ct_all['gta_overlap'] = gdf_ct_all.apply(lambda row: row.geometry.intersection(mpoly_GTA).area / row.geometry.area, axis=1)\n",
    "    gdf_ct_gta = gdf_ct_all[gdf_ct_all.gta_overlap > 0.5]\n",
    "    gdf_ct_gta.to_file(f\"../data/geo/{year}_ct/ct_gta_{year}.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f48d6",
   "metadata": {},
   "source": [
    "Join together CSD/CT boundaries and data, then create a joint geographical dataset which covers the full GTA by CSD's where CT's are missing weighted proportionately by how much they are included.\n",
    "\n",
    "In the case of years without CSD data (<1981), join the CSD geometry from 2021 with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1797336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_census_values_to_gdf(gdf_full, gdf_small, cen_year, cen_var):\n",
    "    cols = YEAR_CODES[cen_year][cen_var]\n",
    "\n",
    "    if len(cols) == 0:  \n",
    "        gdf_small[cen_var] = np.nan\n",
    "        if cen_var == 'num_not_vm_tot':\n",
    "            gdf_small.rename(columns={'num_not_vm_tot': 'num_vm_tot'}, inplace=True)\n",
    "    elif len(cols) > 1:  # New immigrants has multiple tags\n",
    "        gdf_small.loc[:, cen_var] = gdf_full.loc[:, cols].sum(axis=1)\n",
    "    elif cen_var == 'num_not_vm_tot':  # Need to compute total - NOT\n",
    "        pop_total = gdf_full[YEAR_CODES[cen_year]['num_pop_tot'][0]]\n",
    "        non_vm_total = gdf_full[cols[0]]  # Use [0] to get string from list\n",
    "        gdf_small['num_vm_tot'] = pop_total - non_vm_total\n",
    "    else:\n",
    "        gdf_small.loc[:, cen_var] = gdf_full.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3903c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain geography for 2021 CSD data in the GTA\n",
    "gdf_csd_gta_2021 = gpd.read_file(f\"../data/geo/2021_csd/csd_gta_2021.gpkg\")\n",
    "gdf_csd_gta_2021 = gdf_csd_gta_2021[['geosid', 'geometry']]\n",
    "gdf_csd_gta_2021['geosid'] = gdf_csd_gta_2021['geosid'].astype(str)\n",
    "gdf_csd_gta_2021['num_pop_tot'] = np.nan\n",
    "gdf_csd_gta_2021['num_imm_tot'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70262b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "for cen_year in tqdm(CEN_YEARS):\n",
    "    if (cen_year < 1961) or (cen_year == 1966) or (cen_year == 1976):\n",
    "        continue\n",
    "\n",
    "    gdf_ct_gta = gpd.read_file(f\"../data/geo/{cen_year}_ct/ct_gta_{cen_year}.gpkg\")\n",
    "    df_ct_cen = pd.read_csv(f\"../data/census/{cen_year}_ct_wide/census_wide_{cen_year}_ct.csv\")\n",
    "\n",
    "    gdf_ct_gta['geosid'] = gdf_ct_gta['geosid'].astype(str)\n",
    "    df_ct_cen['geosid'] = df_ct_cen['geosid'].astype(str)\n",
    "    df_ct_cen['geosid'] = df_ct_cen['geosid'].apply(lambda x: x[:-2] + '.00' if x.endswith('.0') else x)\n",
    "\n",
    "    gdf_ct_full = pd.merge(\n",
    "        gdf_ct_gta,\n",
    "        df_ct_cen,\n",
    "        on='geosid',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    gdf_ct_small = gdf_ct_full[['geosid', 'geometry']].copy()\n",
    "    add_census_values_to_gdf(gdf_ct_full, gdf_ct_small, cen_year, 'num_pop_tot')\n",
    "    add_census_values_to_gdf(gdf_ct_full, gdf_ct_small, cen_year, 'num_imm_tot')\n",
    "    add_census_values_to_gdf(gdf_ct_full, gdf_ct_small, cen_year, 'num_imm_new')\n",
    "    add_census_values_to_gdf(gdf_ct_full, gdf_ct_small, cen_year, 'num_imm_2nd_tot')\n",
    "    add_census_values_to_gdf(gdf_ct_full, gdf_ct_small, cen_year, 'num_not_vm_tot')\n",
    "\n",
    "    if cen_year >= 1981:\n",
    "        gdf_csd_gta = gpd.read_file(f\"../data/geo/{cen_year}_csd/csd_gta_{cen_year}.gpkg\")\n",
    "        df_csd_cen = pd.read_csv(f\"../data/census/{cen_year}_csd_wide/census_wide_{cen_year}_csd.csv\")\n",
    "        \n",
    "        gdf_csd_gta['geosid'] = gdf_csd_gta['geosid'].astype(str)\n",
    "        df_csd_cen['geosid'] = df_csd_cen['geosid'].astype(str)\n",
    "\n",
    "        gdf_csd_full = pd.merge(\n",
    "            gdf_csd_gta,\n",
    "            df_csd_cen,\n",
    "            on='geosid',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        gdf_csd_small = gdf_csd_full[['geosid', 'geometry']].copy()\n",
    "        add_census_values_to_gdf(gdf_csd_full, gdf_csd_small, cen_year, 'num_pop_tot')\n",
    "        add_census_values_to_gdf(gdf_csd_full, gdf_csd_small, cen_year, 'num_imm_tot')\n",
    "        add_census_values_to_gdf(gdf_csd_full, gdf_csd_small, cen_year, 'num_imm_new')\n",
    "        add_census_values_to_gdf(gdf_csd_full, gdf_csd_small, cen_year, 'num_imm_2nd_tot')\n",
    "        add_census_values_to_gdf(gdf_csd_full, gdf_csd_small, cen_year, 'num_not_vm_tot')\n",
    "\n",
    "    ## Join together CTs and CSDs\n",
    "    # Project geometries to CRS 3857 for accurate area calculations\n",
    "    gdf_ct_small_proj = gdf_ct_small.to_crs(3857)\n",
    "    if cen_year >= 1981:\n",
    "        gdf_csd_small_proj = gdf_csd_small.to_crs(3857)\n",
    "    else:\n",
    "        # For years 1961-1980, use 2021 CSD geography with NaN values\n",
    "        gdf_csd_small_proj = gdf_csd_gta_2021.to_crs(3857)\n",
    "    \n",
    "    # Create a unified geometry of all CTs to identify non-overlapping CSD areas\n",
    "    ct_union = gdf_ct_small_proj.unary_union\n",
    "    \n",
    "    # Calculate the difference between CSD geometries and CT union\n",
    "    gdf_csd_non_overlap = gdf_csd_small_proj.copy()\n",
    "    gdf_csd_non_overlap['geometry'] = gdf_csd_non_overlap.geometry.difference(ct_union)\n",
    "    \n",
    "    # Calculate area ratio for weighting census variables\n",
    "    original_areas = gdf_csd_small_proj.geometry.area\n",
    "    new_areas = gdf_csd_non_overlap.geometry.area\n",
    "    area_ratios = new_areas / original_areas\n",
    "\n",
    "    # Remove minor differences in the geometry \n",
    "    area_ratios[area_ratios < 0.02] = 0\n",
    "    gdf_csd_non_overlap.loc[area_ratios == 0, 'geometry'] = Polygon()\n",
    "    \n",
    "    # Weight census variables by area ratio (only for years with actual CSD data)\n",
    "    if cen_year >= 1981:\n",
    "        census_cols = [col for col in gdf_csd_small.columns if col not in ['geosid', 'geometry']]\n",
    "        for col in census_cols:\n",
    "            gdf_csd_non_overlap[col] = gdf_csd_small[col] * area_ratios\n",
    "    \n",
    "    # Instead of filtering out empty geometries, keep them but set census values to NaN\n",
    "    empty_mask = gdf_csd_non_overlap.is_empty\n",
    "    if empty_mask.any():\n",
    "        census_cols = [col for col in gdf_csd_non_overlap.columns if col not in ['geosid', 'geometry']]\n",
    "        gdf_csd_non_overlap.loc[empty_mask, census_cols] = np.nan\n",
    "    \n",
    "    # Combine CTs and non-overlapping CSDs\n",
    "    gdf_combined = pd.concat([gdf_ct_small_proj, gdf_csd_non_overlap], ignore_index=True)\n",
    "    \n",
    "    # Ensure valid geometries and convert back to original CRS\n",
    "    invalid_mask = ~gdf_combined.is_valid\n",
    "    if invalid_mask.any():\n",
    "        gdf_combined.loc[invalid_mask, 'geometry'] = gdf_combined[invalid_mask].buffer(0)\n",
    "        census_cols = [col for col in gdf_combined.columns if col not in ['geosid', 'geometry']]\n",
    "        gdf_combined.loc[invalid_mask, census_cols] = np.nan\n",
    "    \n",
    "    gdf_combined = gdf_combined.to_crs(gdf_ct_small.crs)\n",
    "    \n",
    "    # Clean data (set any negative values to NaN)\n",
    "    numeric_cols = ['num_imm_tot', 'num_pop_tot', 'num_imm_new', 'num_imm_2nd_tot', 'num_vm_tot']\n",
    "    for col in numeric_cols:\n",
    "        if col in gdf_combined.columns:\n",
    "            gdf_combined[col] = pd.to_numeric(gdf_combined[col], errors='coerce')\n",
    "            if col == 'num_pop_tot':\n",
    "                gdf_combined.loc[gdf_combined[col] <= 0, col] = np.nan\n",
    "            else:\n",
    "                gdf_combined.loc[gdf_combined[col] < 0, col] = np.nan\n",
    "    \n",
    "    # Calculate percentage of immigrants\n",
    "    gdf_combined['pct_imm'] = (gdf_combined['num_imm_tot'] / gdf_combined['num_pop_tot']) * 100\n",
    "    gdf_combined['pct_imm_new'] = (gdf_combined['num_imm_new'] / gdf_combined['num_pop_tot']) * 100\n",
    "    gdf_combined['pct_imm_2nd'] = (gdf_combined['num_imm_2nd_tot'] / gdf_combined['num_pop_tot']) * 100\n",
    "    gdf_combined['pct_vm'] = (gdf_combined['num_vm_tot'] / gdf_combined['num_pop_tot']) * 100\n",
    "    \n",
    "    # Safer coverage gap check\n",
    "    try:\n",
    "        current_coverage = gdf_combined.unary_union\n",
    "        original_coverage = gdf_csd_small_proj.to_crs(gdf_ct_small.crs).unary_union if cen_year >= 1981 else gdf_csd_gta_2021.unary_union\n",
    "        coverage_gap = original_coverage.difference(current_coverage)\n",
    "        \n",
    "        if not coverage_gap.is_empty and coverage_gap.area > 1:  # 1 square meter threshold\n",
    "            gap_row = {\n",
    "                'geosid': 'MISSING',\n",
    "                'geometry': coverage_gap,\n",
    "                'num_pop_tot': np.nan,\n",
    "                'num_imm_tot': np.nan,\n",
    "                'pct_imm': np.nan\n",
    "            }\n",
    "            for col in gdf_combined.columns:\n",
    "                if col not in gap_row:\n",
    "                    gap_row[col] = np.nan\n",
    "            \n",
    "            gap_gdf = gpd.GeoDataFrame([gap_row], crs=gdf_combined.crs)\n",
    "            gdf_combined = pd.concat([gdf_combined, gap_gdf], ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Save the final output\n",
    "    gdf_combined.to_file(f\"../data/immigration/{cen_year}/imm_stats_{cen_year}.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a534150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Manual cleanup of clipping using Lake Simcoe and Lake Scugog first, then running this\n",
    "for cen_year in tqdm(CEN_YEARS):\n",
    "    if (cen_year < 1961) or (cen_year == 1966) or (cen_year == 1976):\n",
    "        continue\n",
    "\n",
    "    gdf_imm_stats = gpd.read_file(f\"../data/immigration/{cen_year}/imm_stats_{cen_year}.gpkg\")\n",
    "    gdf_imm_stats.to_file(f'../static/data/immigration/imm_stats_{cen_year}.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
